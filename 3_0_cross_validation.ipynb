{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation over PHUS\n",
    "\n",
    "We assume that all the observations from the stations within a PHU are more likely to estimate the behaviour of the PHU where they are.\n",
    "\n",
    "The objective of this Notebook is to select the PHU's that have the best stations to estimate the behaviour of the PHU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "from gee_scripts.parameters import explain_vars, regions_ids\n",
    "from scipy.stats import pearsonr\n",
    "from gee_scripts.models import get_regressors\n",
    "import tensorflow as tf\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from gee_scripts.models import split_dataset\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/9_clean_training_data/all_training_data_with_extra_and_locations_and_precipSum.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "assert len(df) == 32783, \"The length of the dataframe is not correct\"\n",
    "\n",
    "region = regions_ids[\"kalimantan\"]\n",
    "df = df[df.region_id.isin(region)]\n",
    "bad_stations = ['batok1','batok2','brg11','brg13','brg16','BRG_620309_01','BRG_620309_02','BRG_630805_01','BRG_630708_01']\n",
    "\n",
    "df = df[~df.id.isin(bad_stations)]\n",
    "\n",
    "assert df[[\"date\"]].dtypes.iloc[0] == \"datetime64[ns]\"\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the figure\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Groundwater level over time\")\n",
    "sns.lineplot(x=\"date\", y=\"gwl_cm\", data=df)\n",
    "\n",
    "# Add title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cros validation loop - PHU ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare different ML algorithms: sradient boosting, random forest, simple neural network, linear model.<br>\n",
    "- Assess performance across different types of slipts of the data (train/test) <br>\n",
    "- Get a distribution of performance metrics through the 10 random splits<br>\n",
    "\n",
    "This comprehensive approach should give us a good understanding of how the models perform under different conditions and how generalizable they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Training types</h2></center>\n",
    "<center><img src = \"img/training_types.jpg\" height=\"400px\"/></center>\n",
    "</br>\n",
    "<center><h2>Evaluation metrics</h2></center>\n",
    "<center><img src = \"img/evaluation_metric.jpg\" height=\"250px\"/></center>\n",
    "</br>\n",
    "<center><h2>PHU Ranking</h2></center>\n",
    "<center><img src = \"img/phu_ranking.jpg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression modles tested\n",
    "\n",
    "<b>Random Forest</b>: This is an ensemble learning method that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random Forest is effective for dealing with large datasets and reducing the risk of overfitting.<br>\n",
    "\n",
    "<b>Gradient Boosting</b>: Gradient Boosting is another ensemble technique that builds models sequentially. Each new model incrementally reduces the errors made by the previous models. It uses a gradient descent algorithm to minimize errors and can be very effective for complex datasets with nonlinear patterns.<br>\n",
    "\n",
    "<b>Sequential (Simple Neural Net)</b>: Often referred to simply as neural networks, these are systems of neurons either in a single layer or multiple layers. Neural networks are designed to recognize patterns in data through a process that mimics the way a human brain operates. They are highly flexible and can be used for both classification and regression tasks.<br>\n",
    "\n",
    "<b>Linear Regression</b>: This is a fundamental statistical approach for modeling the relationship between a scalar dependent variable and one or more explanatory variables (or independent variables). The relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Linear Regression is particularly useful for understanding the strength of the impact of various predictive factors.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "<p style=\"font-size:16px\"><b>Pearson Correlation Coefficient (r)</b>: Measures the linear correlation between the true and predicted values. Values range from -1 to 1, where 1 indicates a perfect positive correlation.</br></br>\n",
    "<b>R-squared Score</b>: Represents the proportion of the variance in the dependent variable that is predictable from the independent variables. Values range from 0 to 1, where 1 indicates that the model explains all the variance.</br></br>\n",
    "<b>Root Mean Squared Error (RMSE)</b>: Measures the average magnitude of the prediction error. Lower values indicate better model performance.</br></br><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(data, target_column, n_splits):\n",
    "    \"\"\"Evaluate the performance of different regression models on the dataset using cross-validation.\"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Loop through each split type\n",
    "    for split_type in [\"station\", \"year\", \"month\"]:\n",
    "        \n",
    "        train_test_splits = split_dataset(data, by=split_type, n_splits=n_splits)\n",
    "\n",
    "        if split_type == \"station\":\n",
    "            split_type = \"id\"\n",
    "\n",
    "        for train_data, test_data in train_test_splits:\n",
    "\n",
    "            if len(test_data) == 0:\n",
    "                results.append({\n",
    "                    \"phu_id\": data[\"phu_id\"].iloc[0],\n",
    "                    \"split_type\": split_type,\n",
    "                    \"no_obs\": len(data),\n",
    "                    \"train_obs\": 0,\n",
    "                    \"test_obs\": 0,\n",
    "                    \"estimator_name\": None,\n",
    "                    \"validation\" : f\"cross validation {split_type}\",\n",
    "                    \"test_ids\": None,\n",
    "                    \"train_ids\": None,\n",
    "                    \"r2_score\": None,\n",
    "                    \"rmse\": None,\n",
    "                    \"pearson_r\": None,\n",
    "                    \"p_value\": None,\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            X_train, X_test = train_data[explain_vars], test_data[explain_vars]\n",
    "            y_train, y_test = train_data[target_column], test_data[target_column]\n",
    "\n",
    "            input_dim = X_train.shape[1]  # Number of explanatory variables\n",
    "\n",
    "            for regr in get_regressors(input_dim):\n",
    "                print(f\"Training {regr.__class__.__name__} on {len(train_data)} observations and testing on {len(test_data)} observations\")\n",
    "\n",
    "                if isinstance(regr, tf.keras.Model):  # Check if the model is a Keras model\n",
    "                    # Neural network requires normalization and batch processing\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_scaled = scaler.fit_transform(X_train)\n",
    "                    X_test_scaled = scaler.transform(X_test)\n",
    "                    \n",
    "                    # Fit the model\n",
    "                    regr.fit(X_train_scaled, y_train, epochs=5, batch_size=8, verbose=0)\n",
    "                    \n",
    "                    # Predict\n",
    "                    y_pred_test = regr.predict(X_test_scaled).flatten()  # Flatten to convert 2D predictions to 1D\n",
    "                else:\n",
    "                    # Fit traditional models\n",
    "                    regr.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Predict\n",
    "                    y_pred_test = regr.predict(X_test)\n",
    "\n",
    "\n",
    "                r, p = pearsonr(y_test, y_pred_test)\n",
    "                r2_score_val = r2_score(y_test, y_pred_test)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "                results.append({\n",
    "                    \"phu_id\": train_data[\"phu_id\"].iloc[0],\n",
    "                    \"no_obs\": len(data),\n",
    "                    \"train_obs\": len(train_data),\n",
    "                    \"test_obs\": len(test_data),\n",
    "                    \"estimator_name\": regr.__class__.__name__,\n",
    "                    \"validation\" : f\"cross validation {split_type}\",\n",
    "                    \"train_ids\": train_data[split_type].unique(),\n",
    "                    \"test_ids\": test_data[split_type].unique(),\n",
    "                    \"r2_score\": r2_score_val,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"pearson_r\": r,\n",
    "                    \"p_value\": p,\n",
    "                })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of observations per PHU\n",
    "sorted([(id_, len(df[df.phu_id == id_])) for id_ in df.phu_id.unique()], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "phu_cross_validation_results = []\n",
    "failed_phus = []\n",
    "errors = {}\n",
    "\n",
    "print(f\"running cross validation on {df.phu_id.nunique()} phu_ids\")\n",
    "\n",
    "for phu_id in df.phu_id.unique():\n",
    "    if  pd.isnull(phu_id):\n",
    "        print(\"Skipping phu_id\", phu_id, \"because it is null\")\n",
    "        continue\n",
    "    print(\"processing phu_id\", phu_id, \"with No. of observations\", len(df[df.phu_id==phu_id]))\n",
    "    filter_condition = df.phu_id==phu_id\n",
    "    train_df = df[filter_condition]\n",
    "    try:\n",
    "        results = evaluate_models(train_df, \"gwl_cm\", n_splits=10)\n",
    "        phu_cross_validation_results.extend(results)\n",
    "    except exception as e:\n",
    "        print(\"Failed to train model on phu_id\", phu_id)\n",
    "        errors[phu] = e\n",
    "        failed_phus.append(phu_id)\n",
    "    finally:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the results\n",
    "results_df = pd.DataFrame(phu_cross_validation_results)\n",
    "# Sort the results by r2_score and phu_id\n",
    "results_df.sort_values(by=[\"r2_score\", \"phu_id\"], ascending=False, inplace=True)\n",
    "# results_df.to_csv(\"data/13_estimation_results/kalimantan_multiple_models_cross_validation_results_sorted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"data/13_estimation_results/center_multiple_models_cross_validation_results_sorted_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming phu_cross_validation_results is a list of dictionaries\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = results_df[['r2_score', 'rmse', 'pearson_r']].describe()\n",
    "\n",
    "# Performance by model type\n",
    "model_performance = results_df.groupby('estimator_name')[['r2_score', 'rmse', 'pearson_r']].mean()\n",
    "\n",
    "# Plotting model performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='estimator_name', y='r2_score', data=results_df)\n",
    "plt.title('Average R2 Score by Model Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Analyze performance by split type\n",
    "split_performance = results_df.groupby('split_type')[['r2_score', 'rmse', 'pearson_r']].mean()\n",
    "\n",
    "# Print the summary statistics and model performance\n",
    "print(summary_stats)\n",
    "print(model_performance)\n",
    "print(split_performance)\n",
    "\n",
    "# Handle failures\n",
    "print(\"Failed PHUs:\", failed_phus)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(test) gwl-modeling",
   "language": "python",
   "name": "gwl-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
