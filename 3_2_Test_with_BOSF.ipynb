{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gee_scripts.parameters import explain_vars\n",
    "from gee_scripts.models import get_random_forest\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from gee_scripts.plots import plot_observed_vs_predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER PARAMETERS\n",
    "\n",
    "# Select the region where to work\n",
    "region = \"kalimantan\"\n",
    "\n",
    "## List of specific id values to remove\n",
    "# These stations were selected based on the results of the previous analysis\n",
    "bad_stations = ['batok1','batok2','brg11','brg13','brg16','BRG_620309_01','BRG_620309_02','BRG_630805_01','BRG_630708_01']\n",
    "\n",
    "best_phus = [350,351,357,379]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/9_clean_training_data/all_training_data_with_extra_and_locations_and_precipSum.csv\", parse_dates=[\"date\"])\n",
    "assert len(df) == 32783, \"The length of the dataframe is not correct\"\n",
    "data = df[(~df.id.isin(bad_stations)) & (df.phu_id.isin(best_phus))].copy()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/7_training_data/bosf/explanatory_with_response_var_and_source_extra_sum_prec_bosf.csv\")\n",
    "test_data = test_data[test_data.source==\"bosf_NASA\"]\n",
    "test_data[\"gwl_cm\"].describe()\n",
    "\n",
    "\n",
    "test_data = test_data[test_data.time_difference<1]\n",
    "train_data = test_data\n",
    "\n",
    "# Plot the gwl_cm variable\n",
    "train_data.gwl_cm.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[\n",
    "    (df.gwl_cm>-50) &\n",
    "    # & (df.gwl_cm<5) \n",
    "    (df.phu_id.isin([379])) \n",
    "    & (~df.id.isin(bad_stations))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_data[explain_vars], test_data[explain_vars]\n",
    "y_train, y_test = train_data[\"gwl_cm\"], test_data[\"gwl_cm\"]\n",
    "\n",
    "print(\"lenght of train and test\", len(X_train), len(X_test))\n",
    "\n",
    "####################### TRAIN\n",
    "\n",
    "regr = get_random_forest()\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred_test = regr.predict(X_test)\n",
    "\n",
    "r, p = pearsonr(y_test, y_pred_test)\n",
    "r2_score_val = r2_score(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "# print all the metrics\n",
    "print(f\"r2_score: {r2_score_val}\")\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"pearson r: {r}\")\n",
    "print(f\"p-value: {p}\")\n",
    "\n",
    "\n",
    "plot_observed_vs_predicted(y_test, y_pred_test, color=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide test/train by random sampling\n",
    "\n",
    "# randomly select 80% as train and the rest as test\n",
    "\n",
    "# train_data = data[data.gwl_cm>-150].sample(frac=0.8)\n",
    "# test_data = data[data.gwl_cm>-150].drop(train_data.index)\n",
    "\n",
    "# best_kalimantan_phus = [357., 297., 350., 351., 352.]\n",
    "\n",
    "# Create a new feature that indicates if an area is flooded or not\n",
    "\n",
    "train_data = df[\n",
    "    # (df.gwl_cm>-150)\n",
    "    # & (df.gwl_cm<5) \n",
    "    (df.phu_id.isin([350, 351, 379, 357])) \n",
    "    & (~df.id.isin(bad_stations))\n",
    "]\n",
    "\n",
    "X_train, X_test = train_data[explain_vars], test_data[explain_vars]\n",
    "y_train, y_test = train_data[\"gwl_cm\"], test_data[\"gwl_cm\"]\n",
    "\n",
    "print(\"lenght of train and test\", len(X_train), len(X_test))\n",
    "\n",
    "####################### TRAIN\n",
    "\n",
    "regr = get_random_forest()\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred_test = regr.predict(X_test)\n",
    "\n",
    "r, p = pearsonr(y_test, y_pred_test)\n",
    "r2_score_val = r2_score(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "# print all the metrics\n",
    "print(f\"r2_score: {r2_score_val}\")\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"pearson r: {r}\")\n",
    "print(f\"p-value: {p}\")\n",
    "\n",
    "\n",
    "plot_observed_vs_predicted(y_test, y_pred_test, color=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwl-modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
