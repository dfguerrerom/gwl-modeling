{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gee_scripts.get_sources import get_explanatory_composite\n",
    "from gee_scripts.parameters import explain_vars\n",
    "from gee_scripts.get_sources import get_s1_dates\n",
    "import datetime\n",
    "\n",
    "from gee_scripts.directories import get_export_folder\n",
    "import ee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train the classifier in GEE and save the model as asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This table contains the training data for the model\n",
    "training_data = ee.FeatureCollection(\"projects/ee-marortpab/assets/FAO/indonesia/gwl/df_with_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee.batch\n",
    "\n",
    "\n",
    "def export_classifier(model_name):\n",
    "    \"\"\"Export and save a classifier to GEE\"\"\"\n",
    "\n",
    "\n",
    "    features=training_data.filter(ee.Filter.eq(model_name, 1))\n",
    "    print(f\"Exporting model {model_name} with {features.size().getInfo()} samples\")\n",
    "\n",
    "    n_trees = 250\n",
    "\n",
    "    classifier = ee.Classifier.smileRandomForest(n_trees).setOutputMode('REGRESSION').train(\n",
    "        features=features, \n",
    "        classProperty = \"gwl_cm\", \n",
    "        inputProperties=explain_vars\n",
    "    )\n",
    "\n",
    "    description = f\"RandomForest_{model_name}_trees_{n_trees}\"\n",
    "\n",
    "    # Create a folder to store the models\n",
    "    model_gee_id = str(get_export_folder(\"models\")/description)\n",
    "\n",
    "    if ee.data.getInfo(model_gee_id):\n",
    "        raise ValueError(f\"Model {model_gee_id} already exists\")\n",
    "\n",
    "    task = ee.batch.Export.classifier.toAsset(classifier, description, model_gee_id)\n",
    "    task.start()\n",
    "\n",
    "    print(f\"Exported model {model_gee_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting model model7 with 19116 samples\n",
      "Exported model projects/sepal-ui-421413/assets/gwl-modeling/models/RandomForest_model7\n"
     ]
    }
   ],
   "source": [
    "# We have intentified three potential models: model5, model7, and model17\n",
    "export_classifier(\"model7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://code.earthengine.google.com/1fd31fe53d5a8cf8b812552f901325a0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_days_offset = 30\n",
    "scale = 100\n",
    "target_date = \"2022-04-21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: closest image is not the target date, using closest image: 2022-04-20 instead\n"
     ]
    }
   ],
   "source": [
    "phus = ee.FeatureCollection(\"users/marortpab/FAO/SEPAL/2023_trainings/smm/AOI__Province__865_PHUs__INDONESIA\")\n",
    "target_phu = phus.filter(ee.Filter.eq(\"PHU_NAME\", \"KHG Sungai Siak - Sungai Kampar\")).geometry()\n",
    "max_days_offset = 30\n",
    "scale = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_dates = get_s1_dates(target_phu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-02'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_date = datetime.datetime.fromtimestamp(s1_dates[0]/1000).strftime('%Y-%m-%d')\n",
    "str_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_estimation(model_name, target_date, target_phu):\n",
    "    \"\"\"Export the estimated GWL image for a given model and target date.\"\"\"\n",
    "\n",
    "    str_date = datetime.datetime.fromtimestamp(target_date/1000).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Get explanatory composite closest to target date\n",
    "    image = get_explanatory_composite(\n",
    "        target_date=str_date, \n",
    "        ee_region=target_phu, \n",
    "        max_days_offset=1\n",
    "    ).select(explain_vars)\n",
    "\n",
    "    output_image_name = f\"{model_name}_PHU_SungaiKampar_{str_date}\"\n",
    "    ee_classifier = ee.Classifier.load(f\"projects/sepal-ui-421413/assets/gwl-modeling/models/RandomForest_{model_name}\")\n",
    "    estimated_image = image.select(explain_vars).classify(ee_classifier).set({\"model\": model_name, \"date\": target_date})\n",
    "\n",
    "    # create export task\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        **{\n",
    "            \"image\": estimated_image,\n",
    "            \"description\": output_image_name,\n",
    "            \"assetId\": str(get_export_folder(output_folder=f\"estimation/{model_name}\")/output_image_name),\n",
    "            \"region\": target_phu,\n",
    "            \"scale\": 100,\n",
    "        }\n",
    "    )\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: closest image is not the target date, using closest image: 2015-01-02 instead\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model7\"\n",
    "tasks = [export_estimation(model_name, target_date, target_phu) for target_date in s1_dates[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[task.start() for task in tasks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Estimate GWL using the trained model\n",
    "\n",
    "If you have a rasterio error, it is because this package is not installed in our virtual environment, to fix this error, you can go to the terminal and:\n",
    "\n",
    "- Go to the gwl-folder (cd \"path_to_gwl-modeling_folder\")\n",
    "- run this command: python3 data/init_venv.py\n",
    "\n",
    "Or in the terminal:\n",
    "\n",
    "- type: activate_venv\n",
    "- search the gwl-modeling virtual environment\n",
    "- write the number of the virtual environment and type enter\n",
    "- type: pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gee_scripts.directories import explanatory_path, output_estimation_path, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_image_name = Path(\"WorkshopIndonesia_test_3.tif\")\n",
    "model_path = Path(model_path/\"PHU_136.joblib\")\n",
    "\n",
    "# load the model with joblib\n",
    "estimator = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the explanatory composite\n",
    "with rio.open(explanatory_path/input_image_name) as src:\n",
    "    img_array = src.read()\n",
    "    meta = src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transposed_img = np.transpose(img_array, (1, 2, 0))\n",
    "reshaped_img = transposed_img.reshape(-1, 28)\n",
    "\n",
    "predicted_values = estimator.predict(reshaped_img)\n",
    "\n",
    "# Reshape the predicted values back to original shape\n",
    "predicted_values = predicted_values.reshape(transposed_img.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape back to 2D grid\n",
    "output_array = predicted_values.reshape((meta['height'], meta['width']))\n",
    "\n",
    "# Update metadata for 1 band output\n",
    "meta.update({'count': 1})\n",
    "\n",
    "# Save to disk\n",
    "with rio.open(output_estimation_path/f\"{model_name.stem}_{input_image_name.stem}_estimated.tif\", 'w', **meta) as dst:\n",
    "    dst.write(output_array, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate GWL over one point in multiple dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/9_clean_training_data/clean_training_data.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all stations with less tan 9 observations\n",
    "min_obs = 9\n",
    "df.groupby('id').agg({'date': 'count'}).sort_values(by='date', ascending=False).reset_index()\n",
    "df = df.groupby('id').filter(lambda group: len(group) >= min_obs)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
