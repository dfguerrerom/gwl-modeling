{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from gee_scripts.models import get_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read phu regions shapefile\n",
    "phu_regions = gpd.read_file(\"data/0_shp/AOI__Province__865_PHUs__INDONESIA.gpkg\")\n",
    "phu_regions = phu_regions.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/9_clean_training_data/clean_training_data.csv\")\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat), crs=\"EPSG:4326\")\n",
    "# do spatial join with phu's\n",
    "df = gpd.sjoin(df, phu_regions, how=\"left\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the number of cases per PHU\n",
    "phu_cases = df.groupby(\"phu_id\").size().reset_index(name=\"observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a boxplot of response var per region but use a small graph size\n",
    "\n",
    "# set the seaborn style and size\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(8,5)})\n",
    "sns.boxplot(x=\"island\", y=\"gwl_cm\", data=df, width=0.5)\n",
    "\n",
    "# Rename x-axis with phu id\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"PHU id\")\n",
    "plt.ylabel(\"Groundwater Level (cm)\")\n",
    "plt.title(\"Groundwater Level Distribution by Island\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a boxplot of response var per region but use a small graph size\n",
    "\n",
    "# set the seaborn style and size\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(8,5)})\n",
    "sns.boxplot(x=\"source\", y=\"gwl_cm\", data=df, width=0.5)\n",
    "\n",
    "# Rename x-axis with phu id\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"source\")\n",
    "plt.ylabel(\"Groundwater Level (cm)\")\n",
    "plt.title(\"Groundwater Level Distribution by source\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a boxplot of response var per region but use a small graph size\n",
    "\n",
    "# set the seaborn style and size\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(8,5)})\n",
    "sns.boxplot(x=\"province\", y=\"gwl_cm\", data=df, width=0.5)\n",
    "\n",
    "# Rename x-axis with phu id\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"PHU id\")\n",
    "plt.ylabel(\"Groundwater Level (cm)\")\n",
    "plt.title(\"Groundwater Level Distribution by Province\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a boxplot showing the number of dates per each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# group by id and get the number of dates for each id\n",
    "group_by = \"id\"\n",
    "df_grouped = df.groupby(group_by).count().reset_index()\n",
    "df_grouped = df_grouped[[group_by, \"date\"]]\n",
    "df_grouped.columns = [\"name\", \"date_count\"]\n",
    "df_grouped.sort_values(by=\"date_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the dimensions of the plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a violin plot for the variable\n",
    "sns.violinplot(x=df_grouped[\"date_count\"])\n",
    "\n",
    "# Set the title and x-axis label\n",
    "plt.title(f\"Frequency dates per point\")\n",
    "plt.xlabel(\"Number of dates per station\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop all stations with less tan 9 observations\n",
    "min_obs = 9\n",
    "df.groupby('id').agg({'date': 'count'}).sort_values(by='date', ascending=False).reset_index()\n",
    "df = df.groupby('id').filter(lambda group: len(group) >= min_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gee_scripts.parameters import explain_vars, response_var\n",
    "print(\"dependent var\", response_var)\n",
    "print(\"explanatory lenght\", len(explain_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All but one test over stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gee_scripts.randomforest import run_randomforest\n",
    "from gee_scripts.randomforest import get_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = 'gwl_cm'\n",
    "\n",
    "high_corr_ids = pd.read_csv(\"data/high_corr_0.2_temporal_variables_station_ids.csv\")\n",
    "high_corr_ids.columns = [\"id\"]\n",
    "\n",
    "training_df = df[\n",
    "    (df.island == \"Kalimantan\") &\n",
    "    (df.id.isin(high_corr_ids.id.unique()))\n",
    "]\n",
    "\n",
    "# Manually selected PHU for training\n",
    "# high_corr_phu_ids = [\n",
    "#     136,\n",
    "#     137,\n",
    "#     138,\n",
    "#     143\n",
    "# ]\n",
    "# training_df = df[\n",
    "#     (df.phu_id.isin(high_corr_phu_ids))\n",
    "# ]\n",
    "\n",
    "stats_df = run_randomforest(training_df, type_=\"allbutone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_heatmap(stats_df, \"r_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_heatmap(stats_df, \"rmse_local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_stations = stats_df[stats_df.rmse_local < 15].sort_values(by=\"r_local\", ascending=False).index\n",
    "best_stations\n",
    "len(best_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with best stations over all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from gee_scripts.parameters import explain_vars, temporal_expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split gdf into good statoins for train\n",
    "gdf_high = training_df[training_df.id.isin(best_stations)].copy()\n",
    "# and bad stations for test\n",
    "gdf_low = training_df[~training_df.id.isin(best_stations)].copy()\n",
    "\n",
    "variable = 'gwl_cm'\n",
    "\n",
    "# create and train classifier\n",
    "regr = get_regressor()\n",
    "regr.fit(gdf_high[explain_vars], gdf_high[variable])\n",
    "\n",
    "row = {}\n",
    "#rmse_list = []\n",
    "for station in gdf_low.id.unique():\n",
    "    explans = []\n",
    "    # apply model to specific station\n",
    "    gdf_test = gdf_low[gdf_low.id == station]\n",
    "    y_pred_test = regr.predict(gdf_test[explain_vars])\n",
    "\n",
    "    # get pearsons r\n",
    "    r, p = pearsonr(gdf_test[variable].values, y_pred_test)\n",
    "    explans.append(r)\n",
    "\n",
    "    explans.append(np.sqrt(mean_squared_error(gdf_test[variable].values, y_pred_test)))\n",
    "\n",
    "    # add correlation of explanatories\n",
    "    for expl in temporal_expl:\n",
    "        explans.append(gdf_test[variable].corr(gdf_test[expl]))\n",
    "     \n",
    "    row[station] = explans\n",
    "    #row[station] = [np.sqrt(mean_squared_error(gdf_test[variable].values, y_pred_test))]\n",
    "    #print(row)\n",
    "    \n",
    "stats_df = pd.DataFrame.from_dict(row, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_heatmap(stats_df, \"r_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_heatmap(stats_df, \"rmse_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_worse_stations = stats_df[stats_df.rmse_local < 15].index\n",
    "best_worse_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf_high.to_file(\"data/0_shp/kalimantan_best_stations.gpkg\", driver=\"GPKG\")\n",
    "len(gdf_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final model bootstraping (test different combinations)\n",
    "\n",
    "The following cells will test different combinations of stations, provinces or phus.\n",
    "After each bootraping, combination, a result containing the average, min, max and median statistics of the different statistical parameters over all the iterations. \n",
    "\n",
    "This result will help to select what is the best combination of stations to produce the final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gee_scripts.randomforest import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bootstrap_stations = list(best_stations) # + list(best_worse_stations)\n",
    "len(bootstrap_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootsrap with only best stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = training_df[training_df.id.isin(best_stations)]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=5, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boostrap with best + best worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = training_df[training_df.id.isin(list(best_stations) + list(best_worse_stations))]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=5, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boostrap by PHU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = df[\n",
    "    (df.phu_id == 136)\n",
    "]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=10, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bootrsap with BRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = df[\n",
    "    (df.source.isin([\"brg\", \"old_brg\"])) & \n",
    "    (df.island == \"Kalimantan\")\n",
    "]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=10, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = df[\n",
    "    (df.source.isin([\"brg\", \"old_brg\"])) & \n",
    "    (df.island == \"Sumatera\")\n",
    "]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=10, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootrsap with PKEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = df[\n",
    "    (df.source.isin([\"pkeg\"])) & \n",
    "    (df.island == \"Sumatera\")\n",
    "]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=10, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = df[\n",
    "    (df.source.isin([\"pkeg\"])) & \n",
    "    (df.island == \"Kalimantan\")\n",
    "]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=10, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boostrap by regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.province.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_df = df[\n",
    "    (df.source.isin([\"brg\", \"brg_old\"])) & \n",
    "    (df.province == \"Central Kalimantan\")\n",
    "]\n",
    "bootstrap_result = bootstrap(df = selected_df, variable=\"gwl_cm\", iterations=10, train_size=0.8)\n",
    "bootstrap_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Final model selection\n",
    "\n",
    "After selecting the best combination of stations that present the best model statistics (r, rmse), the following cell can be used to train and store the last model, replace \"final_df\" with the filters that worked well in the bootraping models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gee_scripts.directories import model_path\n",
    "# Save model to file with not pickle (pickle is not safe) \n",
    "import joblib\n",
    "\n",
    "variable = 'gwl_cm'\n",
    "\n",
    "# Define the filters of the best stations.\n",
    "final_df = df[\n",
    "    (df.phu_id == 136)\n",
    "]\n",
    "\n",
    "regr = get_regressor()\n",
    "regr.fit(final_df[explain_vars], final_df[variable])\n",
    "\n",
    "# Define a name for this model, it will be overwritten if there's something before\n",
    "model_name = \"GIVE_A_MEANINGFUL_NAME_TO_THIS_FILE.joblib\"\n",
    "joblib.dump(regr, model_path/model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(test) gwl-modeling",
   "language": "python",
   "name": "gwl-modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
