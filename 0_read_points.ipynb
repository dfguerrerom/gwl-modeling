{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore data sources from .xslsx files, merge them and save them as .csv\n",
    "\n",
    "ach_path = Path(\"data/2_Achmad/achmed_raw.csv\")\n",
    "wal_path = Path(\"data/3_Waluyo/waluyo_raw.csv\")\n",
    "old_brg_path = Path(\"data/4_brg_old/brg_old.csv\")\n",
    "\n",
    "DATA_COLS = [\"source\", \"id\", \"lon\", \"lat\", \"date\", \"gwl_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ach_df = pd.read_csv(ach_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRGM new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ach_cols_rename = {\n",
    "    \"gwl_rata\" : \"gwl_cm\",\n",
    "}\n",
    "\n",
    "# rename columns\n",
    "ach_df.rename(columns=ach_cols_rename, inplace=True)\n",
    "\n",
    "# Convert date column to datetime\n",
    "ach_df[\"date\"] = pd.to_datetime(ach_df[\"date\"])\n",
    "\n",
    "# multiply gwl_cm by 100 to convert it to cm\n",
    "ach_df[\"gwl_cm\"] = ach_df[\"gwl_cm\"] * 100\n",
    "\n",
    "# set a new column for source\n",
    "ach_df[\"source\"] = \"ach\"\n",
    "\n",
    "ach_df = ach_df[DATA_COLS]\n",
    "ach_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ach_df.id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PKEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wal_cols_rename = {\n",
    "    \"date(dd/mm/yyyy)\" : \"date\",\n",
    "    \"gwl(cm)\" : \"gwl_cm\",\n",
    "    \"coor_y(dd)\" : \"lat\",\n",
    "    \"coor_x(dd)\" : \"lon\",\n",
    "}\n",
    "\n",
    "# Read Waluyo's data\n",
    "wal_df = pd.read_csv(wal_path, sep=\";\")\n",
    "\n",
    "# Rename columns\n",
    "wal_df.rename(columns=wal_cols_rename, inplace=True)\n",
    "\n",
    "# combine \"kode_perusahaan\"\tand \"kode_titik\" to create a unique id\n",
    "wal_df.loc[:, \"id\"] = wal_df[\"kode_perusahaan\"] + \"_\" + wal_df[\"kode_titik\"]\n",
    "\n",
    "# Convert date column to datetime\n",
    "wal_df.loc[:, \"date\"] = pd.to_datetime(wal_df[\"date\"], dayfirst=True)\n",
    "\n",
    "# set a new column for source\n",
    "wal_df[\"source\"] = \"wal\"\n",
    "\n",
    "# Only select columns that are needed\n",
    "wal_df = wal_df[DATA_COLS]\n",
    "wal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous BRG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_brg_df = pd.read_csv(old_brg_path)\n",
    "old_brg_df.loc[:, \"source\"] = \"old_brg\"\n",
    "old_brg_df.loc[:, \"date\"] = pd.to_datetime(old_brg_df[\"date\"], dayfirst=True)\n",
    "\n",
    "# Multiply gwl_cm by 100 to convert it to cm\n",
    "old_brg_df[\"gwl_cm\"] = old_brg_df[\"gwl_cm\"] * 10\n",
    "old_brg_df = old_brg_df[DATA_COLS]\n",
    "old_brg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "df = pd.concat([ach_df, wal_df, old_brg_df], ignore_index=True)\n",
    "\n",
    "# save the dataframe as csv\n",
    "df.to_csv(\"data/field_data_all_with_old.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate dates for each id using the mean value\n",
    "# Group by 'id' and 'date' and calculate the mean value for 'gwl_cm' while keeping other columns\n",
    "\n",
    "print(\"Before removing duplicates\", len(df))\n",
    "\n",
    "agg_dict = {'source':'first','lon':'first','lat':'first','gwl_cm':'mean'}\n",
    "df = df.groupby(['id','date']).agg(agg_dict).reset_index()\n",
    "\n",
    "print(\"After removing duplicates\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below I will remove the duplicated coordinates IDS and keep the first one\n",
    "# get unique lon-lat pairs\n",
    "unique = df[[\"id\", \"lon\", \"lat\"]].drop_duplicates()\n",
    "\n",
    "# Get duplicated lon-lat pairs\n",
    "duplicated = unique[unique.duplicated(subset=[\"lon\", \"lat\"], keep=False)]\n",
    "\n",
    "duplicated = duplicated.drop_duplicates(subset=[\"lon\", \"lat\"], keep=\"first\")\n",
    "\n",
    "# Get the duplicated ids\n",
    "duplicated_ids = duplicated[\"id\"].unique()\n",
    "\n",
    "# # get dataframe without duplicated ids\n",
    "\n",
    "df = df[~df[\"id\"].isin(duplicated_ids)]\n",
    "\n",
    "df.to_csv(\"data/field_data_unique_coords.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique coordinates for each station\n",
    "stations = df[[\"id\", \"source\", \"lon\", \"lat\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(stations.lon, stations.lat)]\n",
    "stations_gdf = GeoDataFrame(stations, geometry=geometry)\n",
    "stations_gdf.crs = \"EPSG:4326\"\n",
    "stations_gdf.to_file(\"data/0_shp/unique_stations_no_repeated.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwl-modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
