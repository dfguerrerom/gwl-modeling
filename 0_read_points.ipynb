{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data sources from .xslsx files, merge them and save them as .csv\n",
    "# ach means Achmad\n",
    "# wal means Waluyo\n",
    "\n",
    "ach_path = Path(\"data/2_Achmad/achmed_raw.csv\")\n",
    "wal_path = Path(\"data/3_Waluyo/waluyo_raw.csv\")\n",
    "old_brg_path = Path(\"data/4_brg_old/brg_old.csv\")\n",
    "\n",
    "DATA_COLS = [\"source\", \"id\", \"lon\", \"lat\", \"date\", \"gwl_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ach_df = pd.read_csv(ach_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>date</th>\n",
       "      <th>gwl_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>-14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>-17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>-20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>-18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>-23.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source             id         lon       lat       date  gwl_cm\n",
       "0    ach  BRG_140301_01  102.099167  1.519444 2018-10-15   -14.4\n",
       "1    ach  BRG_140301_01  102.099167  1.519444 2018-10-16   -17.9\n",
       "2    ach  BRG_140301_01  102.099167  1.519444 2018-10-17   -20.6\n",
       "3    ach  BRG_140301_01  102.099167  1.519444 2018-10-18   -18.1\n",
       "4    ach  BRG_140301_01  102.099167  1.519444 2018-10-19   -23.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ach_cols_rename = {\n",
    "    \"gwl_rata\" : \"gwl_cm\",\n",
    "}\n",
    "\n",
    "# rename columns\n",
    "ach_df.rename(columns=ach_cols_rename, inplace=True)\n",
    "\n",
    "# Convert date column to datetime\n",
    "ach_df[\"date\"] = pd.to_datetime(ach_df[\"date\"])\n",
    "\n",
    "# multiply gwl_cm by 100 to convert it to cm\n",
    "ach_df[\"gwl_cm\"] = ach_df[\"gwl_cm\"] * 100\n",
    "\n",
    "# set a new column for source\n",
    "ach_df[\"source\"] = \"ach\"\n",
    "\n",
    "ach_df = ach_df[DATA_COLS]\n",
    "ach_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BRG_140301_01', 'BRG_140301_02', 'BRG_140302_01', 'BRG_140302_02',\n",
       "       'BRG_140802_02', 'brg8', 'BRG_140802_01', 'BRG_140802_03',\n",
       "       'BRG_140806_01', 'BRG_150710_02', 'BRG_150706_01', 'BRG_150709_01',\n",
       "       'BRG_150709_02', 'BRG_150710_01', 'BRG_150710_03', 'BRG_621107_04',\n",
       "       'BRG_621107_05', 'BRG_621107_06', 'BRG_621107_07', 'BRG_621107_08',\n",
       "       'BRG_627104_06', 'BRG_621103_05', 'BRG_621105_02', 'BRG_621105_03',\n",
       "       'BRG_621107_02', 'BRG_621107_03', 'BRG_621101_02'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ach_df.id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waluyo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48601/2703119350.py:18: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  wal_df.loc[:, \"date\"] = pd.to_datetime(wal_df[\"date\"], dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>date</th>\n",
       "      <th>gwl_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wal</td>\n",
       "      <td>121_APC_A21</td>\n",
       "      <td>96.451939</td>\n",
       "      <td>3.809687</td>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wal</td>\n",
       "      <td>121_APC_A21</td>\n",
       "      <td>96.451939</td>\n",
       "      <td>3.809687</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>-12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wal</td>\n",
       "      <td>121_APC_A21</td>\n",
       "      <td>96.451939</td>\n",
       "      <td>3.809687</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wal</td>\n",
       "      <td>121_APC_A21</td>\n",
       "      <td>96.451939</td>\n",
       "      <td>3.809687</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>-60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wal</td>\n",
       "      <td>121_APC_A21</td>\n",
       "      <td>96.451939</td>\n",
       "      <td>3.809687</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>-25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source           id        lon       lat       date  gwl_cm\n",
       "0    wal  121_APC_A21  96.451939  3.809687 2020-11-14   -10.0\n",
       "1    wal  121_APC_A21  96.451939  3.809687 2020-11-26   -12.0\n",
       "2    wal  121_APC_A21  96.451939  3.809687 2020-12-02   -30.0\n",
       "3    wal  121_APC_A21  96.451939  3.809687 2020-12-16   -60.0\n",
       "4    wal  121_APC_A21  96.451939  3.809687 2021-07-12   -25.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wal_cols_rename = {\n",
    "    \"date(dd/mm/yyyy)\" : \"date\",\n",
    "    \"gwl(cm)\" : \"gwl_cm\",\n",
    "    \"coor_y(dd)\" : \"lat\",\n",
    "    \"coor_x(dd)\" : \"lon\",\n",
    "}\n",
    "\n",
    "# Read Waluyo's data\n",
    "wal_df = pd.read_csv(wal_path, sep=\";\")\n",
    "\n",
    "# Rename columns\n",
    "wal_df.rename(columns=wal_cols_rename, inplace=True)\n",
    "\n",
    "# combine \"kode_perusahaan\"\tand \"kode_titik\" to create a unique id\n",
    "wal_df.loc[:, \"id\"] = wal_df[\"kode_perusahaan\"] + \"_\" + wal_df[\"kode_titik\"]\n",
    "\n",
    "# Convert date column to datetime\n",
    "wal_df.loc[:, \"date\"] = pd.to_datetime(wal_df[\"date\"], dayfirst=True)\n",
    "\n",
    "# set a new column for source\n",
    "wal_df[\"source\"] = \"wal\"\n",
    "\n",
    "# Only select columns that are needed\n",
    "wal_df = wal_df[DATA_COLS]\n",
    "wal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous BRG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48601/1915917322.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  old_brg_df.loc[:, \"date\"] = pd.to_datetime(old_brg_df[\"date\"], dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>date</th>\n",
       "      <th>gwl_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>BRG_150503_01</td>\n",
       "      <td>103.928286</td>\n",
       "      <td>-1.545325</td>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>-3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>BRG_150503_01</td>\n",
       "      <td>103.928286</td>\n",
       "      <td>-1.545325</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>-3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>BRG_150503_01</td>\n",
       "      <td>103.928286</td>\n",
       "      <td>-1.545325</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>-3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>BRG_150503_01</td>\n",
       "      <td>103.928286</td>\n",
       "      <td>-1.545325</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>-3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>BRG_150503_01</td>\n",
       "      <td>103.928286</td>\n",
       "      <td>-1.545325</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>-3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source             id         lon       lat       date  gwl_cm\n",
       "0  old_brg  BRG_150503_01  103.928286 -1.545325 2019-07-06   -3.04\n",
       "1  old_brg  BRG_150503_01  103.928286 -1.545325 2019-07-07   -3.04\n",
       "2  old_brg  BRG_150503_01  103.928286 -1.545325 2019-07-08   -3.04\n",
       "3  old_brg  BRG_150503_01  103.928286 -1.545325 2019-07-09   -3.04\n",
       "4  old_brg  BRG_150503_01  103.928286 -1.545325 2019-07-10   -3.04"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_brg_df = pd.read_csv(old_brg_path)\n",
    "old_brg_df.loc[:, \"source\"] = \"old_brg\"\n",
    "old_brg_df.loc[:, \"date\"] = pd.to_datetime(old_brg_df[\"date\"], dayfirst=True)\n",
    "old_brg_df = old_brg_df[DATA_COLS]\n",
    "old_brg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "df = pd.concat([ach_df, wal_df, old_brg_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# save the dataframe as csv\n",
    "df.to_csv(\"data/field_data_all_with_old.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates 306132\n",
      "After removing duplicates 298827\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate dates for each id using the mean value\n",
    "# Group by 'id' and 'date' and calculate the mean value for 'gwl_cm' while keeping other columns\n",
    "\n",
    "print(\"Before removing duplicates\", len(df))\n",
    "\n",
    "agg_dict = {'source':'first','lon':'first','lat':'first','gwl_cm':'mean'}\n",
    "df = df.groupby(['id','date']).agg(agg_dict).reset_index()\n",
    "\n",
    "print(\"After removing duplicates\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>gwl_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02_AHL_SBG-B076</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>wal</td>\n",
       "      <td>117.007750</td>\n",
       "      <td>3.937760</td>\n",
       "      <td>-37.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02_AHL_SBG-B076</td>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>wal</td>\n",
       "      <td>117.007750</td>\n",
       "      <td>3.937760</td>\n",
       "      <td>-39.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_AHL_SBG-B076</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>wal</td>\n",
       "      <td>117.007750</td>\n",
       "      <td>3.937760</td>\n",
       "      <td>-39.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02_AHL_SBG-B076</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>wal</td>\n",
       "      <td>117.007750</td>\n",
       "      <td>3.937760</td>\n",
       "      <td>-35.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02_AHL_SBG-B076</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>wal</td>\n",
       "      <td>117.007750</td>\n",
       "      <td>3.937760</td>\n",
       "      <td>-34.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298822</th>\n",
       "      <td>kecil1</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>old_brg</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>-3.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298823</th>\n",
       "      <td>kecil1</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>old_brg</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>-3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298824</th>\n",
       "      <td>kecil1</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>old_brg</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>-3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298825</th>\n",
       "      <td>kecil1</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>old_brg</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>-3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298826</th>\n",
       "      <td>kecil1</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>old_brg</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>-3.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id       date   source         lon       lat  gwl_cm\n",
       "0       02_AHL_SBG-B076 2020-11-05      wal  117.007750  3.937760 -37.000\n",
       "1       02_AHL_SBG-B076 2020-11-17      wal  117.007750  3.937760 -39.000\n",
       "2       02_AHL_SBG-B076 2020-12-05      wal  117.007750  3.937760 -39.000\n",
       "3       02_AHL_SBG-B076 2020-12-16      wal  117.007750  3.937760 -35.000\n",
       "4       02_AHL_SBG-B076 2021-01-02      wal  117.007750  3.937760 -34.000\n",
       "...                 ...        ...      ...         ...       ...     ...\n",
       "298822           kecil1 2019-10-26  old_brg  113.805611 -2.856089  -3.021\n",
       "298823           kecil1 2019-10-27  old_brg  113.805611 -2.856089  -3.023\n",
       "298824           kecil1 2019-10-31  old_brg  113.805611 -2.856089  -3.023\n",
       "298825           kecil1 2019-11-02  old_brg  113.805611 -2.856089  -3.023\n",
       "298826           kecil1 2019-11-04  old_brg  113.805611 -2.856089  -3.022\n",
       "\n",
       "[267218 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below I will remove the duplicated coordinates IDS and keep the first one\n",
    "# get unique lon-lat pairs\n",
    "unique = df[[\"id\", \"lon\", \"lat\"]].drop_duplicates()\n",
    "\n",
    "# Get duplicated lon-lat pairs\n",
    "duplicated = unique[unique.duplicated(subset=[\"lon\", \"lat\"], keep=False)]\n",
    "\n",
    "duplicated = duplicated.drop_duplicates(subset=[\"lon\", \"lat\"], keep=\"first\")\n",
    "\n",
    "# Get the duplicated ids\n",
    "duplicated_ids = duplicated[\"id\"].unique()\n",
    "\n",
    "# # get dataframe without duplicated ids\n",
    "\n",
    "df = df[~df[\"id\"].isin(duplicated_ids)]\n",
    "\n",
    "df.to_csv(\"data/field_data_unique_coords_2.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique coordinates for each station\n",
    "stations = df[[\"id\", \"source\", \"lon\", \"lat\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(stations.lon, stations.lat)]\n",
    "stations_gdf = GeoDataFrame(stations, geometry=geometry)\n",
    "stations_gdf.crs = \"EPSG:4326\"\n",
    "stations_gdf.to_file(\"data/0_shp/unique_stations_no_repeated.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unique points (and check they have the same coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids len 2073\n",
      "coords len 2075\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dguerrero/1_modules/gwl-modeling/0_read_points.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dguerrero/1_modules/gwl-modeling/0_read_points.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m shared_ids \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([item \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m shared_ids \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dguerrero/1_modules/gwl-modeling/0_read_points.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Print the results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dguerrero/1_modules/gwl-modeling/0_read_points.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# we'd say that \"half\" of the following have shared coordinates\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dguerrero/1_modules/gwl-modeling/0_read_points.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mlen\u001b[39m(pd\u001b[39m.\u001b[39;49mDataFrame(shared_ids)\u001b[39m.\u001b[39;49miloc[:,\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39munique())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1563\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: \u001b[39mtuple\u001b[39m):\n\u001b[0;32m-> 1563\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tuple_indexer(tup)\n\u001b[1;32m   1564\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1565\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:873\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[39mfor\u001b[39;00m i, k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[1;32m    872\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 873\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_key(k, i)\n\u001b[1;32m    874\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    875\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    876\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLocation based indexing can only have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    877\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m] types\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    878\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1466\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m \u001b[39melif\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 1466\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[1;32m   1467\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m   1468\u001b[0m     \u001b[39m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[1;32m   1469\u001b[0m     \u001b[39m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mToo many indexers\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# get unique ids\n",
    "ids = df[\"id\"].unique()\n",
    "print(\"ids len\", len(ids))\n",
    "\n",
    "# Check that we have the same number of unique coordinates\n",
    "\n",
    "# get unique coordinates\n",
    "coords = df[[\"lon\", \"lat\"]].drop_duplicates()\n",
    "print(\"coords len\", len(coords))\n",
    "\n",
    "# Check the stations that have more than one coordinate\n",
    "\n",
    "# get the number of coordinates per id\n",
    "grouped = df.groupby(['lon', 'lat']).agg({'id': pd.Series.nunique}).reset_index()\n",
    "\n",
    "# Filter groups with more than one unique 'id'\n",
    "shared_coords = grouped[grouped['id'] > 1].reset_index()\n",
    "\n",
    "# For each shared coordinate, list the unique station IDs\n",
    "shared_ids = []\n",
    "for _, row in shared_coords.iterrows():\n",
    "    lon, lat = row['lon'], row['lat']\n",
    "    stations_at_coord = df[(df['lon'] == lon) & (df['lat'] == lat)]['id'].unique()\n",
    "    shared_ids.append(stations_at_coord.tolist())\n",
    "\n",
    "# flatten the list\n",
    "shared_ids = set([item for sublist in shared_ids for item in sublist])\n",
    "\n",
    "# Print the results\n",
    "# we'd say that \"half\" of the following have shared coordinates\n",
    "len(pd.DataFrame(shared_ids).iloc[:,0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert unique ids to shapefile \n",
    "\n",
    "Note that unique ids contains duplicated coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26642/4115086215.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_only_locations[\"date\"] = df_only_locations[\"date\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Export unique point ID's as shapefile\n",
    "\n",
    "df_only_locations = df.drop_duplicates(subset=[\"id\"])\n",
    "\n",
    "# Transfor date to string to avoid errors when exporting to shapefile\n",
    "df_only_locations[\"date\"] = df_only_locations[\"date\"].astype(str)\n",
    "\n",
    "df_only_locations = gpd.GeoDataFrame(df_only_locations, geometry=gpd.points_from_xy(df_only_locations[\"lon\"], df_only_locations[\"lat\"]))\n",
    "df_only_locations.crs = \"EPSG:4326\"\n",
    "df_only_locations.to_file(\"data/merged_df.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### (test()) Create a random sample of 3 points to extract their SM from the images\n",
    "\n",
    "# Create a random sample of 3 points to extract their SM from the images\n",
    "test_sample = gpd.GeoDataFrame(df_only_locations.sample(3, random_state=42))\n",
    "\n",
    "# Export the sample as shapefile\n",
    "test_sample.to_file(\"data/0_shp/test_sample.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>smm_value</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>date</th>\n",
       "      <th>point_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/sepal-user/soil_moisture/kalimantan_isla...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>(114.542846, -2.520543)</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>199_GAL_G80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/sepal-user/soil_moisture/kalimantan_isla...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>(114.657132, -2.52298)</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>199_GAL_T16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/sepal-user/soil_moisture/kalimantan_isla...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>(114.678142, -2.514387)</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>199_GAL_U23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/sepal-user/soil_moisture/kalimantan_isla...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>(114.686607, -2.50288)</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>199_GAL_U29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/sepal-user/soil_moisture/kalimantan_isla...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>(114.697252, -2.484188)</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>199_GAL_U38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427752</th>\n",
       "      <td>/home/sepal-user/soil_moisture/papua_dan/close...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>(133.13999, -2.925532)</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>271_RSP_J73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427753</th>\n",
       "      <td>/home/sepal-user/soil_moisture/papua_dan/close...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>(133.145243, -2.935706)</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>271_RSP_K75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427754</th>\n",
       "      <td>/home/sepal-user/soil_moisture/papua_dan/close...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>(133.13741, -2.945648)</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>271_RSP_L72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427755</th>\n",
       "      <td>/home/sepal-user/soil_moisture/papua_dan/close...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>(133.137354, -2.953089)</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>271_RSP_M72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427756</th>\n",
       "      <td>/home/sepal-user/soil_moisture/papua_dan/close...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135.275777, -3.407239)</td>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>138_NBR_M13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427757 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    image  smm_value  \\\n",
       "0       /home/sepal-user/soil_moisture/kalimantan_isla...       24.0   \n",
       "1       /home/sepal-user/soil_moisture/kalimantan_isla...       22.0   \n",
       "2       /home/sepal-user/soil_moisture/kalimantan_isla...       19.0   \n",
       "3       /home/sepal-user/soil_moisture/kalimantan_isla...       20.0   \n",
       "4       /home/sepal-user/soil_moisture/kalimantan_isla...       22.0   \n",
       "...                                                   ...        ...   \n",
       "427752  /home/sepal-user/soil_moisture/papua_dan/close...       29.0   \n",
       "427753  /home/sepal-user/soil_moisture/papua_dan/close...       27.0   \n",
       "427754  /home/sepal-user/soil_moisture/papua_dan/close...       23.0   \n",
       "427755  /home/sepal-user/soil_moisture/papua_dan/close...       22.0   \n",
       "427756  /home/sepal-user/soil_moisture/papua_dan/close...        NaN   \n",
       "\n",
       "                     coordinate       date     point_id  \n",
       "0       (114.542846, -2.520543) 2023-04-16  199_GAL_G80  \n",
       "1        (114.657132, -2.52298) 2023-04-16  199_GAL_T16  \n",
       "2       (114.678142, -2.514387) 2023-04-16  199_GAL_U23  \n",
       "3        (114.686607, -2.50288) 2023-04-16  199_GAL_U29  \n",
       "4       (114.697252, -2.484188) 2023-04-16  199_GAL_U38  \n",
       "...                         ...        ...          ...  \n",
       "427752   (133.13999, -2.925532) 2020-12-06  271_RSP_J73  \n",
       "427753  (133.145243, -2.935706) 2020-12-06  271_RSP_K75  \n",
       "427754   (133.13741, -2.945648) 2020-12-06  271_RSP_L72  \n",
       "427755  (133.137354, -2.953089) 2020-12-06  271_RSP_M72  \n",
       "427756  (135.275777, -3.407239) 2022-01-06  138_NBR_M13  \n",
       "\n",
       "[427757 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import PosixPath\n",
    "import datetime\n",
    "\n",
    "smm_df = pd.read_csv(\"data/6_extracted_sm_data/all_extracted_data.csv\")\n",
    "\n",
    "# convert date to datetime\n",
    "smm_df[\"date\"] = pd.to_datetime(smm_df[\"date\"])\n",
    "smm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join smm_df with data df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>date</th>\n",
       "      <th>gwl_cm</th>\n",
       "      <th>image</th>\n",
       "      <th>smm_value</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>point_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>-18.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>-23.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source             id         lon       lat       date  gwl_cm image  \\\n",
       "0    ach  BRG_140301_01  102.099167  1.519444 2018-10-15   -14.4   NaN   \n",
       "1    ach  BRG_140301_01  102.099167  1.519444 2018-10-16   -17.9   NaN   \n",
       "2    ach  BRG_140301_01  102.099167  1.519444 2018-10-17   -20.6   NaN   \n",
       "3    ach  BRG_140301_01  102.099167  1.519444 2018-10-18   -18.1   NaN   \n",
       "4    ach  BRG_140301_01  102.099167  1.519444 2018-10-19   -23.1   NaN   \n",
       "\n",
       "   smm_value coordinate point_id  \n",
       "0        NaN        NaN      NaN  \n",
       "1        NaN        NaN      NaN  \n",
       "2        NaN        NaN      NaN  \n",
       "3        NaN        NaN      NaN  \n",
       "4        NaN        NaN      NaN  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join the two dataframes based on their point_id and date\n",
    "# If the point_id and date are the same, the SM value will be added to the df\n",
    "# If the point_id and date are not the same, the SM value will be NaN\n",
    "\n",
    "df_with_sm_data = df.merge(smm_df, how=\"left\", left_on=[\"id\", \"date\"], right_on=[\"point_id\", \"date\"])\n",
    "df_with_sm_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the columns that are needed\n",
    "\n",
    "cols_to_export = [\n",
    "    \"source\",\n",
    "    \"id\",\n",
    "    \"lon\",\n",
    "    \"lat\",\n",
    "    \"date\",\n",
    "    \"gwl_cm\",\n",
    "    \"smm_value\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sm_data[cols_to_export].to_csv(\"data/field_data_with_sm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find stations with the same coordinate pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find stations with the same coordinate pair\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
