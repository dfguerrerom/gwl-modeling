{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following notebook will get two different datasets of explanatory variables: temporal an non-temporal\n",
    "# related. \n",
    "# In order to improve the speed time, this notebook will create the respective datasets and it will send a task to \n",
    "# EarthEngine with a ReduceByRegion operation, we have proved that this method is faster than using the individual\n",
    "# calls to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective would be to loop over the points or the dates...<br>\n",
    "After testing this script https://code.earthengine.google.com/b18e876cca44266be704924b7354ddff <br>\n",
    "I found out that the best way to do it is to loop over the dates, and then pass the reduceregions. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>date</th>\n",
       "      <th>gwl_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>-14.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>-17.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>-20.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>-18.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ach</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>-23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274261</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>kecil1</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>-3.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274262</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>kecil1</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>2019-10-27</td>\n",
       "      <td>-3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274263</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>kecil1</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>-3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274264</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>kecil1</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>-3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274265</th>\n",
       "      <td>old_brg</td>\n",
       "      <td>kecil1</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>-3.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274266 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source             id         lon       lat       date  gwl_cm\n",
       "0           ach  BRG_140301_01  102.099167  1.519444 2018-10-15 -14.400\n",
       "1           ach  BRG_140301_01  102.099167  1.519444 2018-10-16 -17.900\n",
       "2           ach  BRG_140301_01  102.099167  1.519444 2018-10-17 -20.600\n",
       "3           ach  BRG_140301_01  102.099167  1.519444 2018-10-18 -18.100\n",
       "4           ach  BRG_140301_01  102.099167  1.519444 2018-10-19 -23.100\n",
       "...         ...            ...         ...       ...        ...     ...\n",
       "274261  old_brg         kecil1  113.805611 -2.856089 2019-10-26  -3.021\n",
       "274262  old_brg         kecil1  113.805611 -2.856089 2019-10-27  -3.023\n",
       "274263  old_brg         kecil1  113.805611 -2.856089 2019-10-31  -3.023\n",
       "274264  old_brg         kecil1  113.805611 -2.856089 2019-11-02  -3.023\n",
       "274265  old_brg         kecil1  113.805611 -2.856089 2019-11-04  -3.022\n",
       "\n",
       "[274266 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/field_data_unique_coords.csv')\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "high_corr_ids = pd.read_csv('data/ids_high_corr.csv')\n",
    "len(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_coords = df[df.id.isin(high_corr_ids.id)][[\"id\", \"lon\", \"lat\"]].drop_duplicates()\n",
    "unique_coords.head()\n",
    "len(unique_coords)\n",
    "\n",
    "# Convert them as a geodataframe and save them\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(unique_coords.lon, unique_coords.lat)]\n",
    "gdf = gpd.GeoDataFrame(unique_coords, geometry=geometry)\n",
    "# gdf.crs = {'init': 'epsg:4326'}\n",
    "# gdf.to_file(\"data/0_shp/high_corr_stations.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MULTIPOLYGON (((96.37854 4.01317, 96.76923 3.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MULTIPOLYGON (((101.88541 0.86904, 102.68539 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((102.96446 -0.63790, 104.82488 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MULTIPOLYGON (((108.80620 0.62719, 110.20152 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MULTIPOLYGON (((111.96893 -3.78203, 112.26660 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>MULTIPOLYGON (((140.00836 -7.80760, 140.75163 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           geometry\n",
       "0   1  MULTIPOLYGON (((96.37854 4.01317, 96.76923 3.9...\n",
       "1   2  MULTIPOLYGON (((101.88541 0.86904, 102.68539 0...\n",
       "2   3  MULTIPOLYGON (((102.96446 -0.63790, 104.82488 ...\n",
       "3   4  MULTIPOLYGON (((108.80620 0.62719, 110.20152 0...\n",
       "4   5  MULTIPOLYGON (((111.96893 -3.78203, 112.26660 ...\n",
       "5   6  MULTIPOLYGON (((140.00836 -7.80760, 140.75163 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read regions shapefile\n",
    "\n",
    "\n",
    "# I have two regions, first is to only the high correlated stations and the second is all the stations\n",
    "gdf_regions = gpd.GeoDataFrame.from_file(\"data/0_shp/regions_to_request_explanatory.gpkg\")\n",
    "# gdf_regions = gpd.GeoDataFrame.from_file(\"data/0_shp/regions_to_request_explanatory_all.gpkg\")\n",
    "gdf_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33545, 60)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/field_data_unique_coords.csv')\n",
    "df[\"date\"] = pd.to_datetime(df.date)\n",
    "\n",
    "# To only get the high correlated stations, uncomment the following lines\n",
    "high_corr_ids = pd.read_csv('data/ids_high_corr.csv')\n",
    "df = df[df['id'].isin(high_corr_ids['id'])]\n",
    "\n",
    "# Remove those date where the gwl measure is out of reasonable range\n",
    "upper_thres = 20\n",
    "lower_thres = -100\n",
    "\n",
    "df = df[(df.gwl_cm < upper_thres) & (df.gwl_cm > lower_thres)]\n",
    "\n",
    "# save the final points\n",
    "\n",
    "# df.to_csv('field_data_high_corr.csv', index=False)\n",
    "\n",
    "# Get the coordinates of the individual points\n",
    "\n",
    "unique_coords = df[[\"id\", 'lon', 'lat']].drop_duplicates()\n",
    "len(df), len(unique_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "from gee_scripts.get_sources import get_s1_image, get_gldas, get_gpm\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>id_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93142</th>\n",
       "      <td>15_RAPP_TP-I-53</td>\n",
       "      <td>102.015869</td>\n",
       "      <td>0.563137</td>\n",
       "      <td>POINT (102.01587 0.56314)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_left         lon       lat                   geometry  \\\n",
       "93142  15_RAPP_TP-I-53  102.015869  0.563137  POINT (102.01587 0.56314)   \n",
       "\n",
       "       index_right  id_right  \n",
       "93142            1         2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create geodataframe from x y coordinates\n",
    "\n",
    "gdf_unique_coords = gpd.GeoDataFrame(unique_coords, geometry=gpd.points_from_xy(unique_coords.lon, unique_coords.lat), crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "# Add the region id to each point\n",
    "\n",
    "gdf_unique_coords = gpd.sjoin(gdf_unique_coords, gdf_regions[[\"id\", \"geometry\"]], how=\"left\", predicate=\"within\")\n",
    "\n",
    "\n",
    "# I need to extract all the dates from the first group of points\n",
    "# first get the ids of the first group of points\n",
    "\n",
    "gdf_unique_coords[gdf_unique_coords.id_left == \"15_RAPP_TP-I-53\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get temporal explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_temporal_non_resample_at_all_region_1_dates_485_points_2_with_date\n",
      "All_temporal_non_resample_at_all_region_2_dates_626_points_11_with_date\n",
      "All_temporal_non_resample_at_all_region_3_dates_1737_points_13_with_date\n",
      "All_temporal_non_resample_at_all_region_4_dates_653_points_12_with_date\n",
      "All_temporal_non_resample_at_all_region_5_dates_1542_points_21_with_date\n",
      "All_temporal_non_resample_at_all_region_6_dates_479_points_1_with_date\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_selectors = [\"system:index\", \"lat\", \"lon\", \"id\", \"date\"]\n",
    "s1_selectors = [\"LIA\", \"VH\", \"VV\", \"VVVH_ratio\", \"angle\"]\n",
    "gldas_selectors = ['sm_1', 'sm_3', 'sm_7', 'sm_30']\n",
    "gpm_selectors = ['precipitation', 'prec_3', 'prec_7', 'prec_30']\n",
    "\n",
    "\n",
    "def get_temporal_explanatory(region_id):\n",
    "   \"\"\"Get the explanatory temporal based variables\"\"\"\n",
    "\n",
    "   region = gdf_regions[gdf_regions.id == region_id].to_crs(\"EPSG:4326\")[:]\n",
    "   dates = df[df.id.isin(gdf_unique_coords[gdf_unique_coords.id_right == region_id].id_left.unique())].date.unique()\n",
    "   points = gdf_unique_coords[gdf_unique_coords.id_right == region_id][[\"id_left\", \"geometry\"]].rename(columns={\"id_left\": \"id\"}).to_crs(\"EPSG:4326\")\n",
    "\n",
    "   # print(len(dates), len(points))\n",
    "   # Convert to ee elements\n",
    "\n",
    "   ee_dates = ee.FeatureCollection(ee.List([ ee.Feature(None, {\"date\": date}) for date in dates]))\n",
    "   ee_points = ee.FeatureCollection(points.__geo_interface__)\n",
    "   ee_region = ee.FeatureCollection(region.__geo_interface__)\n",
    "\n",
    "   def get_sources(date_feature):\n",
    "      \n",
    "      date_range = ee.Date(date_feature.get(\"date\")).getRange('day')\n",
    "\n",
    "      s1_composite = get_s1_image(date_range, ee_region)\n",
    "\n",
    "      return s1_composite.set({\n",
    "         \"numberOfBands\" : s1_composite.bandNames().size(),\n",
    "         \"date\" : ee.Date(date_feature.get(\"date\"))\n",
    "         })\n",
    "      \n",
    "   def reduce_composite(composite):\n",
    "      \n",
    "      # Filter the extra data with the matching date\n",
    "      date = composite.get(\"date\")\n",
    "      date_range = ee.Date(date).getRange('day')\n",
    "\n",
    "      gldas_composite = get_gldas(date_range, ee_region)\n",
    "      gpm_composite = get_gpm(date_range, ee_region)\n",
    "\n",
    "      composite = (ee.Image(composite)\n",
    "            .addBands(gldas_composite)\n",
    "            .addBands(gpm_composite)\n",
    "      )\n",
    "      \n",
    "      return composite.reduceRegions(**{\n",
    "         \"collection\" : ee_points,\n",
    "         \"reducer\" : ee.Reducer.first(),\n",
    "         \"scale\" : 10,\n",
    "         \"tileScale\" : 16\n",
    "      }).filter(ee.Filter.notNull(['VH'])).map(lambda feature: feature.set({\n",
    "         \"date\" : date\n",
    "      }))\n",
    "\n",
    "\n",
    "   task = (ee_dates\n",
    "         .map(get_sources)\n",
    "         .filter(ee.Filter.gt('numberOfBands', 0))\n",
    "         .map(reduce_composite).flatten()\n",
    "   )\n",
    "\n",
    "   ee_task = ee.batch.Export.table.toDrive(**{\n",
    "      \"collection\": task, \n",
    "      \"folder\" : \"INDONESIA_GWL\",\n",
    "      \"description\": f\"All_temporal_non_resample_region_{region_id}_dates_{len(dates)}_points_{len(points)}\",\n",
    "      \"selectors\": base_selectors + s1_selectors + gldas_selectors + gpm_selectors\n",
    "   })\n",
    "\n",
    "   # Uncoment to start the task\n",
    "   # ee_task.start()\n",
    "\n",
    "   print(f\"All_temporal_non_resample_at_all_region_{region_id}_dates_{len(dates)}_points_{len(points)}_with_date\",)\n",
    "\n",
    "\n",
    "[get_temporal_explanatory(region_id) for region_id in gdf_regions.id.unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get \"yearly\" temporal explanatory variables (Hansen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gee_scripts.get_sources import get_hansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hansen_year_2018_points_60_f\n",
      "Hansen_year_2019_points_60_f\n",
      "Hansen_year_2020_points_60_f\n",
      "Hansen_year_2021_points_60_f\n",
      "Hansen_year_2022_points_60_f\n",
      "Hansen_year_2023_points_60_f\n"
     ]
    }
   ],
   "source": [
    "hansen_selectors = [\"year\", \"B3\",\"B4\",\"B5\",\"B7\",\"ndvi\",\"ndmi\",\"ndbri\"]\n",
    "\n",
    "# get all the years from the field data\n",
    "years = sorted([y for y in df.date.dt.year.unique() if y != 2013] )\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    points = df[[\"id\", \"lon\", \"lat\"]].drop_duplicates()\n",
    "    points = gpd.GeoDataFrame(points, geometry=gpd.points_from_xy(points.lon, points.lat), crs=\"EPSG:4326\")\n",
    "    ee_points = ee.FeatureCollection(points.__geo_interface__)\n",
    "\n",
    "    image = get_hansen(year)\n",
    "\n",
    "    result = image.reduceRegions(**{\n",
    "        \"collection\" : ee_points,\n",
    "        \"reducer\" : ee.Reducer.first(),\n",
    "        \"scale\" : 30,\n",
    "        \"tileScale\" : 16\n",
    "    }).map(lambda feature: feature.set(\"year\", str(year)))\n",
    "\n",
    "    ee_task = ee.batch.Export.table.toDrive(**{\n",
    "        \"collection\": result, \n",
    "        \"folder\" : \"INDONESIA_GWL\",\n",
    "        \"description\": f\"Hansen_year_{year}_points_{len(points)}_f\",\n",
    "        \"selectors\": base_selectors + hansen_selectors\n",
    "    })\n",
    "\n",
    "    print(f\"Hansen_year_{year}_points_{len(points)}_f\")\n",
    "\n",
    "    # ee_task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get non temporal explanatory variables (others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gee_scripts.get_sources import get_srtm, get_globcover, get_gedi, get_gldas_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll try to get all the points at once, not by region (so we won't filter by region)\n",
    "region = gdf_regions.to_crs(\"EPSG:4326\")[:]\n",
    "ee_region = ee.FeatureCollection(region.__geo_interface__)\n",
    "points = gdf_unique_coords[[\"id_left\", \"geometry\"]].rename(columns={\"id_left\": \"id\"}).to_crs(\"EPSG:4326\")\n",
    "ee_points = ee.FeatureCollection(points.__geo_interface__)\n",
    "len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite = (\n",
    "    get_srtm()\n",
    "        .addBands(get_globcover())\n",
    "        .addBands(get_gedi(ee_region))\n",
    "        .addBands(get_gldas_stats(ee_region))\n",
    ")\n",
    "composite.bandNames().getInfo()\n",
    "\n",
    "result = composite.reduceRegions(**{\n",
    "    \"collection\" : ee_points,\n",
    "    \"reducer\" : ee.Reducer.first(),\n",
    "    \"scale\" : 10,\n",
    "    \"tileScale\" : 16\n",
    "}).filter(ee.Filter.notNull(['canopy_height']))\n",
    "\n",
    "ee_task = ee.batch.Export.table.toDrive(**{\n",
    "    \"collection\": result, \n",
    "    \"folder\" : \"INDONESIA_GWL\",\n",
    "    \"description\": f\"All_Non_temporal_points_{len(points)}\",\n",
    "    \"selectors\": base_selectors + ['elevation', 'aspect', 'slope', 'land_cov', 'canopy_height', \"gldas_mean\", \"gldas_stddev\"]\n",
    "})\n",
    "\n",
    "# Uncoment to start the task\n",
    "# ee_task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge explanatory variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Read temporal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanatory_path = Path(\"data/7_training_data/\")\n",
    "temporal_file_names = [\n",
    "    \"High_corr_All_temporal_non_resample_region_1_dates_485_points_2.csv\",\n",
    "    \"High_corr_All_temporal_non_resample_region_2_dates_626_points_11.csv\",\n",
    "    \"High_corr_All_temporal_non_resample_region_3_dates_1737_points_13.csv\",\n",
    "    \"High_corr_All_temporal_non_resample_region_4_dates_653_points_12.csv\",\n",
    "    \"High_corr_All_temporal_non_resample_region_5_dates_1542_points_21.csv\",\n",
    "    \"High_corr_All_temporal_non_resample_region_6_dates_479_points_1.csv\",\n",
    "]\n",
    "\n",
    "# temporal_file_names = [\n",
    "#     \"All_temporal_non_resample_region_10_dates_846_points_77.csv\",\n",
    "#     \"All_temporal_non_resample_region_1_dates_520_points_24.csv\",\n",
    "#     \"All_temporal_non_resample_region_2_dates_1773_points_149.csv\",\n",
    "#     \"All_temporal_non_resample_region_3_dates_479_points_1.csv\",\n",
    "#     \"All_temporal_non_resample_region_4_dates_988_points_348.csv\",\n",
    "#     \"All_temporal_non_resample_region_5_dates_1796_points_717.csv\",\n",
    "#     \"All_temporal_non_resample_region_6_dates_489_points_43.csv\",\n",
    "#     \"All_temporal_non_resample_region_7_dates_1274_points_477.csv\",\n",
    "#     \"All_temporal_non_resample_region_8_dates_1671_points_221.csv\",\n",
    "#     \"All_temporal_non_resample_region_9_dates_379_points_17.csv\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_cols = [\n",
    "    'id', 'lat', 'lon', \"date\", 'LIA', 'VH', 'VV', 'VVVH_ratio', 'angle',\n",
    "    'sm_1', 'sm_3', 'sm_7', 'sm_30', 'precipitation',\n",
    "    'prec_3', 'prec_7', 'prec_30'\n",
    "]\n",
    "\n",
    "def add_date_to_explanatory_df(region_id, explain_df):\n",
    "    \"\"\"Add the corresponding date to the explanatory dataframe.\n",
    "\n",
    "    As the result from GEE didn't come with the date, we'll need to add it manually.\n",
    "    For each of the .csv results, we have to use the \"dates\" list that was used to get the data,\n",
    "    and by its index, we can merge the date to the dataframe.\n",
    "    \n",
    "    For each region we will have different dates.\n",
    "    \"\"\"\n",
    "\n",
    "    dates = pd.DataFrame(\n",
    "        df[df.id.isin(gdf_unique_coords[gdf_unique_coords.id_right == region_id].id_left.unique())].date.unique(),\n",
    "        columns=[\"date\"]\n",
    "    ).reset_index()\n",
    "\n",
    "    # Get the date of the measurement based on the \"system:index\" col\n",
    "    explain_df[\"date_idx\"] = explain_df[\"system:index\"].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "\n",
    "    # return explain_df.merge(dates, left_on=\"date_idx\", right_on=\"index\")\n",
    "    return explain_df.merge(dates, left_on=\"date_idx\", right_on=\"index\")[temporal_cols]\n",
    "\n",
    "\n",
    "\n",
    "# get and concatenate all the dataframes\n",
    "temp_explanatory_dfs = pd.concat([\n",
    "    add_date_to_explanatory_df(region_id, explain_df) \n",
    "    for region_id, explain_df \n",
    "    in enumerate(\n",
    "        [\n",
    "            pd.read_csv(explanatory_path/file_name) \n",
    "            for file_name \n",
    "            in temporal_file_names\n",
    "        ], \n",
    "        start=1\n",
    "        )\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have checked this value and compared it with the latest request I did when I assigned directly the date\n",
    "assert temp_explanatory_dfs[(temp_explanatory_dfs.id==\"15_RAPP_TP-I-53\") & (temp_explanatory_dfs.date == \"2022-11-22\")][\"LIA\"].values[0] == 33.80583090268845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that dates assignation are correct\n",
    "assert temp_explanatory_dfs[temp_explanatory_dfs.id == \"BRG_910111_01\"].date.dt.year.unique().tolist() == [2018, 2019, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Hansen yearly variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanatory_path = Path(\"data/7_training_data/\")\n",
    "hansen_file_names = [\n",
    "    \"Hansen_year_2018_points_2075_f.csv\",\n",
    "    \"Hansen_year_2019_points_2075_f.csv\",\n",
    "    \"Hansen_year_2020_points_2075_f.csv\",\n",
    "    \"Hansen_year_2021_points_2075_f.csv\",\n",
    "    \"Hansen_year_2022_points_2075_f.csv\",\n",
    "    \"Hansen_year_2023_points_2075_f.csv\"\n",
    "]\n",
    "\n",
    "hansen_df = pd.concat([\n",
    "    pd.read_csv(explanatory_path/file_name) \n",
    "    for file_name \n",
    "    in hansen_file_names\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Read non temporal explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the non-temporal variables are the same for all the points, we just need to duplicate \n",
    "# their results into each of the dates of the points.\n",
    "# i.e. 1 point with 10 dates will have the same non-temporal variables for each of the 10 dates.\n",
    "\n",
    "non_temporal_file_name = \"All_Non_temporal_points_2074.csv\"\n",
    "non_temporal_df = pd.read_csv(explanatory_path/non_temporal_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final explanatory variables dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:index</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B7</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndmi</th>\n",
       "      <th>ndbri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.519444</td>\n",
       "      <td>102.099167</td>\n",
       "      <td>BRG_140301_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>66</td>\n",
       "      <td>27</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.159236</td>\n",
       "      <td>0.542373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1797</td>\n",
       "      <td>1.451944</td>\n",
       "      <td>102.181944</td>\n",
       "      <td>BRG_140301_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.159236</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2376</td>\n",
       "      <td>1.511780</td>\n",
       "      <td>102.158660</td>\n",
       "      <td>BRG_140302_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>-0.013514</td>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4173</td>\n",
       "      <td>1.516389</td>\n",
       "      <td>102.433056</td>\n",
       "      <td>BRG_140302_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.092025</td>\n",
       "      <td>0.471074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5970</td>\n",
       "      <td>0.830883</td>\n",
       "      <td>102.354165</td>\n",
       "      <td>BRG_140802_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "      <td>46</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>-0.114504</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>273175</td>\n",
       "      <td>-2.573375</td>\n",
       "      <td>114.022576</td>\n",
       "      <td>ij2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.221374</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>273254</td>\n",
       "      <td>-1.238478</td>\n",
       "      <td>103.589975</td>\n",
       "      <td>jambi1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>273497</td>\n",
       "      <td>-0.210225</td>\n",
       "      <td>109.394853</td>\n",
       "      <td>kalbar1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>86</td>\n",
       "      <td>43</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.338462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>273890</td>\n",
       "      <td>-2.319728</td>\n",
       "      <td>114.058131</td>\n",
       "      <td>kalteng1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.224806</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>274228</td>\n",
       "      <td>-2.856089</td>\n",
       "      <td>113.805611</td>\n",
       "      <td>kecil1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>21</td>\n",
       "      <td>83</td>\n",
       "      <td>62</td>\n",
       "      <td>26</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.144828</td>\n",
       "      <td>0.522936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12450 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      system:index       lat         lon             id  date  year  B3  B4  \\\n",
       "0                0  1.519444  102.099167  BRG_140301_01   NaN  2018  16  91   \n",
       "1             1797  1.451944  102.181944  BRG_140301_02   NaN  2018  19  91   \n",
       "2             2376  1.511780  102.158660  BRG_140302_01   NaN  2018  25  73   \n",
       "3             4173  1.516389  102.433056  BRG_140302_02   NaN  2018  18  89   \n",
       "4             5970  0.830883  102.354165  BRG_140802_02   NaN  2018  25  58   \n",
       "...            ...       ...         ...            ...   ...   ...  ..  ..   \n",
       "2070        273175 -2.573375  114.022576            ij2   NaN  2023  18  80   \n",
       "2071        273254 -1.238478  103.589975         jambi1   NaN  2023  16  78   \n",
       "2072        273497 -0.210225  109.394853        kalbar1   NaN  2023  30  87   \n",
       "2073        273890 -2.319728  114.058131       kalteng1   NaN  2023  16  79   \n",
       "2074        274228 -2.856089  113.805611         kecil1   NaN  2023  21  83   \n",
       "\n",
       "      B5  B7      ndvi      ndmi     ndbri  \n",
       "0     66  27  0.700935  0.159236  0.542373  \n",
       "1     66  28  0.654545  0.159236  0.529412  \n",
       "2     75  39  0.489796 -0.013514  0.303571  \n",
       "3     74  32  0.663551  0.092025  0.471074  \n",
       "4     73  46  0.397590 -0.114504  0.115385  \n",
       "...   ..  ..       ...       ...       ...  \n",
       "2070  51  20  0.632653  0.221374  0.600000  \n",
       "2071  64  26  0.659574  0.098592  0.500000  \n",
       "2072  86  43  0.487179  0.005780  0.338462  \n",
       "2073  50  19  0.663158  0.224806  0.612245  \n",
       "2074  62  26  0.596154  0.144828  0.522936  \n",
       "\n",
       "[12450 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hansen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat_x</th>\n",
       "      <th>lon_x</th>\n",
       "      <th>date</th>\n",
       "      <th>LIA</th>\n",
       "      <th>VH</th>\n",
       "      <th>VV</th>\n",
       "      <th>VVVH_ratio</th>\n",
       "      <th>angle</th>\n",
       "      <th>sm_1</th>\n",
       "      <th>...</th>\n",
       "      <th>gldas_mean</th>\n",
       "      <th>gldas_stddev</th>\n",
       "      <th>year</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B7</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndmi</th>\n",
       "      <th>ndbri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121_APC_D15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>37.158626</td>\n",
       "      <td>-13.377886</td>\n",
       "      <td>-6.305714</td>\n",
       "      <td>0.188173</td>\n",
       "      <td>39.002327</td>\n",
       "      <td>36.214001</td>\n",
       "      <td>...</td>\n",
       "      <td>35.598789</td>\n",
       "      <td>3.224160</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121_APC_D15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>37.852636</td>\n",
       "      <td>-12.313376</td>\n",
       "      <td>-4.441834</td>\n",
       "      <td>0.300894</td>\n",
       "      <td>36.006908</td>\n",
       "      <td>41.771999</td>\n",
       "      <td>...</td>\n",
       "      <td>35.598789</td>\n",
       "      <td>3.224160</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121_APC_D15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>37.155728</td>\n",
       "      <td>-14.935464</td>\n",
       "      <td>-7.701659</td>\n",
       "      <td>0.137663</td>\n",
       "      <td>38.999432</td>\n",
       "      <td>38.425999</td>\n",
       "      <td>...</td>\n",
       "      <td>35.598789</td>\n",
       "      <td>3.224160</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121_APC_D15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>37.159135</td>\n",
       "      <td>-14.816424</td>\n",
       "      <td>-6.980119</td>\n",
       "      <td>0.167454</td>\n",
       "      <td>39.002838</td>\n",
       "      <td>35.361000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.598789</td>\n",
       "      <td>3.224160</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121_APC_D15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>37.158385</td>\n",
       "      <td>-13.969044</td>\n",
       "      <td>-5.805131</td>\n",
       "      <td>0.222621</td>\n",
       "      <td>39.002090</td>\n",
       "      <td>35.499001</td>\n",
       "      <td>...</td>\n",
       "      <td>35.598789</td>\n",
       "      <td>3.224160</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>61</td>\n",
       "      <td>22</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>0.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>BRG_910111_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>41.714628</td>\n",
       "      <td>-13.912240</td>\n",
       "      <td>-10.221497</td>\n",
       "      <td>0.054404</td>\n",
       "      <td>42.762909</td>\n",
       "      <td>32.912998</td>\n",
       "      <td>...</td>\n",
       "      <td>31.034153</td>\n",
       "      <td>4.342498</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>-0.140741</td>\n",
       "      <td>0.104762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>BRG_910111_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>39.653029</td>\n",
       "      <td>-11.491989</td>\n",
       "      <td>-6.076784</td>\n",
       "      <td>0.175861</td>\n",
       "      <td>38.837509</td>\n",
       "      <td>38.230999</td>\n",
       "      <td>...</td>\n",
       "      <td>31.034153</td>\n",
       "      <td>4.342498</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>-0.140741</td>\n",
       "      <td>0.104762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>BRG_910111_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>41.714839</td>\n",
       "      <td>-12.510206</td>\n",
       "      <td>-7.792358</td>\n",
       "      <td>0.110149</td>\n",
       "      <td>42.763123</td>\n",
       "      <td>34.505001</td>\n",
       "      <td>...</td>\n",
       "      <td>31.034153</td>\n",
       "      <td>4.342498</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>-0.140741</td>\n",
       "      <td>0.104762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139</th>\n",
       "      <td>BRG_910111_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>39.657848</td>\n",
       "      <td>-14.591243</td>\n",
       "      <td>-7.201469</td>\n",
       "      <td>0.155738</td>\n",
       "      <td>38.842331</td>\n",
       "      <td>35.603001</td>\n",
       "      <td>...</td>\n",
       "      <td>31.034153</td>\n",
       "      <td>4.342498</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>-0.140741</td>\n",
       "      <td>0.104762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10140</th>\n",
       "      <td>BRG_910111_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>41.709631</td>\n",
       "      <td>-17.024296</td>\n",
       "      <td>-8.877924</td>\n",
       "      <td>0.109640</td>\n",
       "      <td>42.757912</td>\n",
       "      <td>33.424000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.034153</td>\n",
       "      <td>4.342498</td>\n",
       "      <td>2020</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>77</td>\n",
       "      <td>47</td>\n",
       "      <td>0.183673</td>\n",
       "      <td>-0.140741</td>\n",
       "      <td>0.104762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10141 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  lat_x  lon_x       date        LIA         VH  \\\n",
       "0        121_APC_D15    NaN    NaN 2021-07-03  37.158626 -13.377886   \n",
       "1        121_APC_D15    NaN    NaN 2021-07-09  37.852636 -12.313376   \n",
       "2        121_APC_D15    NaN    NaN 2021-07-15  37.155728 -14.935464   \n",
       "3        121_APC_D15    NaN    NaN 2021-07-27  37.159135 -14.816424   \n",
       "4        121_APC_D15    NaN    NaN 2021-08-08  37.158385 -13.969044   \n",
       "...              ...    ...    ...        ...        ...        ...   \n",
       "10136  BRG_910111_01    NaN    NaN 2020-03-21  41.714628 -13.912240   \n",
       "10137  BRG_910111_01    NaN    NaN 2020-03-30  39.653029 -11.491989   \n",
       "10138  BRG_910111_01    NaN    NaN 2020-04-02  41.714839 -12.510206   \n",
       "10139  BRG_910111_01    NaN    NaN 2020-04-11  39.657848 -14.591243   \n",
       "10140  BRG_910111_01    NaN    NaN 2020-04-14  41.709631 -17.024296   \n",
       "\n",
       "              VV  VVVH_ratio      angle       sm_1  ...  gldas_mean  \\\n",
       "0      -6.305714    0.188173  39.002327  36.214001  ...   35.598789   \n",
       "1      -4.441834    0.300894  36.006908  41.771999  ...   35.598789   \n",
       "2      -7.701659    0.137663  38.999432  38.425999  ...   35.598789   \n",
       "3      -6.980119    0.167454  39.002838  35.361000  ...   35.598789   \n",
       "4      -5.805131    0.222621  39.002090  35.499001  ...   35.598789   \n",
       "...          ...         ...        ...        ...  ...         ...   \n",
       "10136 -10.221497    0.054404  42.762909  32.912998  ...   31.034153   \n",
       "10137  -6.076784    0.175861  38.837509  38.230999  ...   31.034153   \n",
       "10138  -7.792358    0.110149  42.763123  34.505001  ...   31.034153   \n",
       "10139  -7.201469    0.155738  38.842331  35.603001  ...   31.034153   \n",
       "10140  -8.877924    0.109640  42.757912  33.424000  ...   31.034153   \n",
       "\n",
       "       gldas_stddev  year  B3  B4  B5  B7      ndvi      ndmi     ndbri  \n",
       "0          3.224160  2021  15  96  61  22  0.729730  0.222930  0.627119  \n",
       "1          3.224160  2021  15  96  61  22  0.729730  0.222930  0.627119  \n",
       "2          3.224160  2021  15  96  61  22  0.729730  0.222930  0.627119  \n",
       "3          3.224160  2021  15  96  61  22  0.729730  0.222930  0.627119  \n",
       "4          3.224160  2021  15  96  61  22  0.729730  0.222930  0.627119  \n",
       "...             ...   ...  ..  ..  ..  ..       ...       ...       ...  \n",
       "10136      4.342498  2020  40  58  77  47  0.183673 -0.140741  0.104762  \n",
       "10137      4.342498  2020  40  58  77  47  0.183673 -0.140741  0.104762  \n",
       "10138      4.342498  2020  40  58  77  47  0.183673 -0.140741  0.104762  \n",
       "10139      4.342498  2020  40  58  77  47  0.183673 -0.140741  0.104762  \n",
       "10140      4.342498  2020  40  58  77  47  0.183673 -0.140741  0.104762  \n",
       "\n",
       "[10141 rows x 35 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the non-temporal variables with the temporal ones\n",
    "\n",
    "explanatory_df = temp_explanatory_dfs.merge(non_temporal_df, on=\"id\")\n",
    "len(explanatory_df)\n",
    "\n",
    "# Merge hansen data with year and id\n",
    "explanatory_df[\"year\"] = explanatory_df.date.dt.year\n",
    "hansen_df[\"year\"] = hansen_df[\"year\"].astype(int)\n",
    "explanatory_df = explanatory_df.merge(hansen_df[[\"id\"] + hansen_selectors], on=[\"id\", \"year\"], how=\"left\")\n",
    "\n",
    "# I get more values here because I have requested Hansen for all the years\n",
    "explanatory_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_vars = [\n",
    "    'id', 'date', 'LIA', 'VH', 'VV', 'VVVH_ratio',\n",
    "    'angle', 'sm_1', 'sm_3', 'sm_7', 'sm_30', 'precipitation', 'prec_3',\n",
    "    'prec_7', 'prec_30', 'elevation',\n",
    "    'aspect', 'slope', 'land_cov', 'canopy_height', 'gldas_mean',\n",
    "    'gldas_stddev', 'B3', 'B4',\n",
    "    'B5', 'B7', 'ndvi', 'ndmi', 'ndbri'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL STEP: Merge explanatory variables with response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanatory_with_response_var = df[[\"id\", \"date\", \"gwl_cm\", \"lat\", \"lon\"]].merge(explanatory_df[export_vars], on=[\"id\", \"date\"])\n",
    "\n",
    "# Add day of the year as a variable\n",
    "explanatory_with_response_var[\"doy\"] = explanatory_with_response_var.date.dt.dayofyear\n",
    "explanatory_with_response_var.to_csv(\"data/7_training_data/explanatory_with_response_var.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'gwl_cm', 'lat', 'lon', 'LIA', 'VH', 'VV', 'VVVH_ratio',\n",
       "       'angle', 'sm_1', 'sm_3', 'sm_7', 'sm_30', 'precipitation', 'prec_3',\n",
       "       'prec_7', 'prec_30', 'elevation', 'aspect', 'slope', 'land_cov',\n",
       "       'canopy_height', 'gldas_mean', 'gldas_stddev', 'B3', 'B4', 'B5', 'B7',\n",
       "       'ndvi', 'ndmi', 'ndbri', 'doy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanatory_with_response_var.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
